{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#data manip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#data viz\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#custom packages\n",
    "import database_utility\n",
    "import baseball_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite_file = 'baseball_data.sqlite'\n",
    "dh = database_utility.DatabaseHelper(sqlite_file, 'baseball_key_joiner.csv')\n",
    "#This will give a ValueError when using pd.read_json if the path doesn't exist\n",
    "filepath = r'C:\\Users\\Chris\\Google Drive\\Programming\\Baseball\\Web Scraping\\bbref_scraper\\bbref_scraper\\bbref.jl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_df, pitching_df = dh.load_data(preload=False, path2017=\"Web Scraping/bbref_scraper/bbref_scraper/bbref.jl\", path2018=\"Web Scraping/bbref_2018.jl\", write_csv=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Load Raw Data</h4>\n",
    "\n",
    "The first step is to load in the raw data we want to use and trim it down to the appropriate timeframe we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load csvs!\n",
      "CSV's Loaded!! Returning batting and pitching df\n",
      "Accessing statcast_cache...\n",
      "If dates are missing try rebuilding cache...\n",
      "Gathering player lookup table. This may take a moment.\n",
      "Aggregating data...\n",
      "Merging bbref and statcast data...\n",
      "Batting FD Score calculated! Returning data..\n",
      "Wall time: 5min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#i exclude the last 2 months of the season which is validation data\n",
    "batting_df = dh.calc_batting_fd_score(start_date = '2015-01-01', end_date = '2018-07-31')\n",
    "batting_df = batting_df[batting_df['player'].notnull()]\n",
    "#batting_df = batting_df[batting_df['year'] == 2015]\n",
    "batting_df['fd_score'] = batting_df['fd_score'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load csvs!\n",
      "CSV's Loaded!! Returning batting and pitching df\n",
      "Calculating FanDuel pitching score...\n"
     ]
    }
   ],
   "source": [
    "pitching_df = dh.calc_pitching_fd_score()\n",
    "#pitching_df = pitching_df[pitching_df['year'] == 2015]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Feature Engineering </h4> \n",
    "\n",
    "The next step is to create (or load) any features we want from the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5> Create Features </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_fe = baseball_models.FeatureEngineer(df=batting_df)\n",
    "pitching_fe = baseball_models.FeatureEngineer(df=pitching_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pitch_life_avgs = pitching_fe.calc_lifetime_avg()\n",
    "pitch_rolling_avgs = pitching_fe.calc_rolling_avg()\n",
    "pitch_ytd_avgs = pitching_fe.calc_ytd_avgs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1B) +( 2 x 2B) + ( 3 x 3B) + ( 4 x HR) / AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batting_fe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batting_fe' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bat_life_avgs = batting_fe.calc_lifetime_avg()\n",
    "bat_rolling_avgs = batting_fe.calc_rolling_avg()\n",
    "bat_ytd_avgs = batting_fe.calc_ytd_avgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THESE CALCS SHOULD GO IN A FILE\n",
    "bat_start_pitcher_matchups = pd.read_csv(\"CSV/starting_pitcher_matchups_all.csv\")\n",
    "bat_start_pitcher_matchups.drop(columns=['Unnamed: 0', 'batter', 'pitcher', 'game_date'], inplace=True)\n",
    "\n",
    "#calculate some statistics from the raw data\n",
    "bat_start_pitcher_matchups['ab'] = bat_start_pitcher_matchups.drop(['walk', 'hit_by_pitch', 'sac_fly', 'sac_fly_double_play', 'sac_bunt', 'sac_bunt_double_play', 'catcher_interf'], axis=1).sum(axis=1)\n",
    "\n",
    "bat_start_pitcher_matchups['pa'] = bat_start_pitcher_matchups.sum(axis=1)\n",
    "\n",
    "bat_start_pitcher_matchups['slugging_perc'] = (bat_start_pitcher_matchups['single'] + (2*bat_start_pitcher_matchups['double']) + \\\n",
    "                                            (3*bat_start_pitcher_matchups['triple']) + (4*bat_start_pitcher_matchups['home_run']))/ \\\n",
    "                                            bat_start_pitcher_matchups['ab']\n",
    "\n",
    "bat_start_pitcher_matchups['hits'] = bat_start_pitcher_matchups['single'] + bat_start_pitcher_matchups['double'] + bat_start_pitcher_matchups['triple'] + bat_start_pitcher_matchups['home_run']\n",
    "bat_start_pitcher_matchups['batting_avg'] = bat_start_pitcher_matchups['hits']/bat_start_pitcher_matchups['ab']\n",
    "\n",
    "bat_start_pitcher_matchups['on_base_perc'] = (bat_start_pitcher_matchups['hits'] + bat_start_pitcher_matchups['walk'] + bat_start_pitcher_matchups['hit_by_pitch'])/bat_start_pitcher_matchups['pa']\n",
    "\n",
    "#only keep these relevent statistics\n",
    "bat_start_pitcher_matchups = bat_start_pitcher_matchups[['ab', 'pa', 'slugging_perc', 'hits', 'batting_avg', 'on_base_perc', 'game_id']]\n",
    "\n",
    "new_cols = []\n",
    "for col in bat_start_pitcher_matchups.columns:\n",
    "    if col != 'game_id':\n",
    "        new_cols.append(col + '_matchup_hist')\n",
    "        \n",
    "new_cols.append('game_id')\n",
    "\n",
    "bat_start_pitcher_matchups.columns = new_cols\n",
    "\n",
    "bat_start_pitcher_matchups.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the features into one dataframe we can train the model on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_feature_df = pd.merge(pitch_life_avgs, pitch_rolling_avgs, on='game_id')\n",
    "pitch_feature_df = pd.merge(pitch_feature_df, pitch_ytd_avgs, on='game_id')\n",
    "pitch_feature_df = pd.merge(pitch_feature_df, pitching_df[['game_id', 'fd_score']], on='game_id')\n",
    "\n",
    "#i think duplications are happening due to doubleheaders when the merges occur, hence the drop duplicates at the end\n",
    "bat_feature_df = pd.merge(bat_life_avgs, bat_rolling_avgs, on='game_id')\n",
    "bat_feature_df = pd.merge(bat_feature_df, bat_ytd_avgs, on='game_id')\n",
    "bat_feature_df = pd.merge(bat_feature_df, bat_start_pitcher_matchups, on = 'game_id')\n",
    "bat_feature_df = pd.merge(bat_feature_df, batting_df[['game_id', 'fd_score']], on='game_id')\n",
    "bat_feature_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to write results to CSV to cache for the future\n",
    "pitch_feature_df.to_csv(\"CSV/pitch_feature_df.csv\", index=False, header=True)\n",
    "bat_feature_df.to_csv(\"CSV/bat_feature_df.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD FEATURES IF THEY EXIST ALREADY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if they exist already and you just want to add new features - load them up here and then add new ones\n",
    "pitch_feature_df = pd.read_csv(\"CSV/pitch_feature_df.csv\")\n",
    "bat_feature_df = pd.read_csv(\"CSV/bat_feature_df.csv\")\n",
    "\n",
    "#example of adding new features\n",
    "#pitch_feature_df = pd.merge(pitch_feature_df, new_features, on='game_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Train the model </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e43ad8f4ee26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbaseball_models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTimeSeriesSplit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "import baseball_models\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the pitching model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iter: 1\n",
      "Iter 1 took 2.3429982662200928 seconds.\n",
      "Running iter: 2\n",
      "Iter 2 took 6.272998571395874 seconds.\n",
      "Running iter: 3\n",
      "Iter 3 took 9.729013681411743 seconds.\n",
      "Running iter: 4\n",
      "Iter 4 took 13.361008882522583 seconds.\n",
      "Running iter: 5\n",
      "Iter 5 took 22.499536514282227 seconds.\n"
     ]
    }
   ],
   "source": [
    "pitching_cv = baseball_models.CrossValidator()\n",
    "\n",
    "#make sure we are sorted by time (days)\n",
    "pitch_feature_df.sort_values(by='game_id',inplace=True)\n",
    "\n",
    "X_pitch, y_pitch, tscv_pitch = pitching_cv.train_test_split(pitch_feature_df.drop('fd_score', axis=1), pitch_feature_df['fd_score'], num_splits=5)\n",
    "\n",
    "#remove features that we know aren't valuable from previous feature engineering\n",
    "#we can add new features that we are trying for the first time in the 'new_features parameter'\n",
    "#life_features = pitch_life_avgs.drop('game_id', axis=1).columns\n",
    "\n",
    "#add other new features here...\n",
    "\n",
    "X_pitch = pitching_cv.clean_for_model(X_pitch, pitching=True)\n",
    "\n",
    "#initialize the model\n",
    "xgbreg_pitch = xgboost.XGBRegressor(silent=True, \n",
    "                      scale_pos_weight=1,\n",
    "                      learning_rate=0.01,  \n",
    "                      colsample_bytree = 0.4,\n",
    "                      subsample = 0.8, \n",
    "                      n_estimators=100, \n",
    "                      reg_alpha = 0.3,\n",
    "                      max_depth=4, \n",
    "                      gamma=10)\n",
    "\n",
    "pitching_cv.cross_validate(X_pitch, y_pitch, tscv_pitch, xgbreg_pitch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the batting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running iter: 1\n",
      "Iter 1 took 11.170775413513184 seconds.\n",
      "Running iter: 2\n",
      "Iter 2 took 24.343040943145752 seconds.\n",
      "Running iter: 3\n",
      "Iter 3 took 35.57539200782776 seconds.\n",
      "Running iter: 4\n",
      "Iter 4 took 51.21678161621094 seconds.\n",
      "Running iter: 5\n",
      "Iter 5 took 67.06810069084167 seconds.\n"
     ]
    }
   ],
   "source": [
    "batting_cv = baseball_models.CrossValidator()\n",
    "\n",
    "#make sure we are sorted by time (days)\n",
    "bat_feature_df.sort_values(by='game_id',inplace=True)\n",
    "\n",
    "X_bat, y_bat, tscv_bat = batting_cv.train_test_split(bat_feature_df.drop('fd_score', axis=1), bat_feature_df['fd_score'], num_splits=5)\n",
    "\n",
    "#remove features that we know aren't valuable from previous feature engineering\n",
    "#we can add new features that we are trying for the first time in the 'new_features parameter'\n",
    "life_features = bat_life_avgs.drop('game_id', axis=1).columns\n",
    "matchup_features = bat_start_pitcher_matchups.drop('game_id', axis = 1).columns\n",
    "\n",
    "new_columns = list(life_features)+list(matchup_features)\n",
    "\n",
    "#add other new features as a list here...\n",
    "\n",
    "X_bat = batting_cv.clean_for_model(X_bat, batting=True, new_features = new_columns)\n",
    "\n",
    "#initialize the model\n",
    "xgbreg_bat = xgboost.XGBRegressor(silent=True, \n",
    "                      scale_pos_weight=1,\n",
    "                      learning_rate=0.01,  \n",
    "                      colsample_bytree = 0.4,\n",
    "                      subsample = 0.8, \n",
    "                      n_estimators=100, \n",
    "                      reg_alpha = 0.3,\n",
    "                      max_depth=4, \n",
    "                      gamma=10)\n",
    "\n",
    "batting_cv.cross_validate(X_bat, y_bat, tscv_bat, xgbreg_bat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_cv.log_model(notes=\"Trained for 5 iterations with new pitcher matchup features added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(xgbreg_bat, open(\"xgb_bat.pickle\", 'wb'))\n",
    "pickle.dump(batting_cv, open(\"batting_cv.pickle\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Make predictions! </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this lookup key table is needed to sync up to rotoguru data to make the final predictions\n",
    "player_lookup = pd.read_csv(\"CSV/player_lookup_2015.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to bring in Rotoguru data to get salary information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotoguru  = pd.read_csv('mlb-dbd-2015.csv', sep=\":\", index_col=False)\n",
    "rotoguru.columns = ['GID', 'MLB_ID','Name_Last_First','Name_First_Last',' P/H','Hand','Date','Team','Oppt','H/A','Game#','Game_ID','Gametime_ET','Team_score','Oppt_score','Home_Ump','Temp','Condition','W_speed','W_dir','ADI','prior_ADI','GS','GP','Pos','Order','Oppt_pitch_hand','Oppt_pich_GID','Oppt_pitch_MLB_ID','Oppt_pitch_Name','PA','wOBA_num','IP','W/L/S','QS','FD_points','DK_points','DD_points','SF_points','FD_salary','DK_salary','DD_salary','SF_salary','FD_pos','DK_pos','DD_pos','SF_pos']\n",
    "rotoguru.drop(rotoguru.tail(1).index,inplace=True)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "#get dates as normal formats\n",
    "rotoguru['Date'] = rotoguru['Date'].astype(str).str[:-2]\n",
    "rotoguru['Date'] = pd.to_datetime(rotoguru['Date'])\n",
    "rotoguru['last_name'], rotoguru['first_name'] = zip(*rotoguru['Name_Last_First'].apply(lambda x: x.split(',')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine Rotoguru data with batting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we zip up the game id and the prediction - lets get those into a dataframe and then we can join back in other info\n",
    "bat_pred_df = pd.DataFrame(batting_cv.id_preds, columns=['fd_score', 'game_id'])\n",
    "\n",
    "#join in other relevant columns\n",
    "bat_pred_df = pd.merge(bat_pred_df, batting_df[['game_id', 'player', 'game_date']], on ='game_id')\n",
    "bat_pred_df = pd.merge(bat_pred_df, player_lookup[['key_bbref', 'key_mlbam']], left_on='player', right_on='key_bbref')\n",
    "#convert to datetime to be able to merge with rotoguru\n",
    "bat_pred_df['game_date'] = pd.to_datetime(bat_pred_df['game_date'])\n",
    "bat_pred_df.drop('player', axis=1, inplace=True)\n",
    "\n",
    "bat_pred_df = pd.merge(bat_pred_df, rotoguru[['MLB_ID', 'first_name', 'last_name', 'Date', 'Team', 'Pos', 'FD_points', 'FD_salary']], left_on=['game_date', 'key_mlbam'],\n",
    "        right_on=['Date', 'MLB_ID'])\n",
    "\n",
    "#drop extraneous columns\n",
    "bat_pred_df.drop(['MLB_ID', 'Date'], axis=1, inplace=True)\n",
    "#there are a couple rows that don't show up in the rotoguru data\n",
    "bat_pred_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for the pitching dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_pred_df = pd.DataFrame(pitching_cv.id_preds, columns=['fd_score', 'game_id'])\n",
    "\n",
    "#join in other relevant columns\n",
    "pitch_pred_df = pd.merge(pitch_pred_df, pitching_df[['game_id', 'player', 'game_date']], on ='game_id')\n",
    "pitch_pred_df = pd.merge(pitch_pred_df, player_lookup[['key_bbref', 'key_mlbam']], left_on='player', right_on='key_bbref')\n",
    "#convert to datetime to be able to merge with rotoguru\n",
    "pitch_pred_df['game_date'] = pd.to_datetime(pitch_pred_df['game_date'])\n",
    "pitch_pred_df.drop('player', axis=1, inplace=True)\n",
    "\n",
    "pitch_pred_df = pd.merge(pitch_pred_df, rotoguru[['MLB_ID', 'first_name', 'last_name', 'Date', 'Team', 'Pos', 'FD_points', 'FD_salary']], left_on=['game_date', 'key_mlbam'],\n",
    "        right_on=['Date', 'MLB_ID'])\n",
    "\n",
    "#drop extraneous columns\n",
    "pitch_pred_df.drop(['MLB_ID', 'Date'], axis=1, inplace=True)\n",
    "#there are a couple rows that don't show up in the rotoguru data\n",
    "pitch_pred_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the two together to hand to the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = pd.concat([bat_pred_df, pitch_pred_df], axis=0)\n",
    "\n",
    "#exclude postseason days\n",
    "prediction_df = prediction_df[prediction_df['game_date'] < '2015-10-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do some final cleaning of the positions to prepare for optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.loc[(prediction_df['Pos'] == 'C') | (prediction_df['Pos'] == '1B'), 'Pos'] = '1B/C'\n",
    "prediction_df.loc[(prediction_df['Pos'] == 'CF') | (prediction_df['Pos'] == 'LF') | (prediction_df['Pos'] == 'RF'), 'Pos'] = 'OF'\n",
    "prediction_df.loc[prediction_df['Pos'] == 'DH', 'Pos'] = 'UTIL'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> OPTIMIZZZEEE </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pydfs_lineup_optimizer import get_optimizer, Site, Sport, Player\n",
    "\n",
    "optimizer = get_optimizer(Site.FANDUEL, Sport.BASEBALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select a random day to test - we will want to be more methodical and test a series of days going forward I think\n",
    "unique_test_days = prediction_df['game_date'].astype(str).unique()\n",
    "rand_day = unique_test_days[np.random.randint(0, len(unique_test_days))]\n",
    "\n",
    "#need to add\n",
    "\n",
    "day_to_predict_df = prediction_df[prediction_df['game_date'] == rand_day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are predicting lineups for:  2015-09-15\n"
     ]
    }
   ],
   "source": [
    "print(\"We are predicting lineups for: \", rand_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 309 players to select a lineup from\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {} players to select a lineup from\".format(day_to_predict_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the list of player objects to hand to the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = list(day_to_predict_df.apply(get_player_object, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> THE PREDICTED LINEUP </h3>\n",
    "\n",
    "AKA holy shit it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. P      Jacob deGrom                 P     NYM            24.128  11100.0$  \n",
      " 2. C/1B   Dan Murphy                   2B/1B NYM            6.08    3400.0$   \n",
      " 3. 2B     Brian Dozier                 2B    MIN            6.865   3000.0$   \n",
      " 4. 3B     Nolan Arenado                3B    COL            7.554   4000.0$   \n",
      " 5. SS     Alexei Ramirez               SS/P  CHW            7.954   3300.0$   \n",
      " 6. OF     Yoenis Cespedes              OF    NYM            7.564   5100.0$   \n",
      " 7. OF     Jose Bautista                OF    TOR            8.164   5400.0$   \n",
      " 8. OF     Bryce Harper                 OF    WAS            7.972   5300.0$   \n",
      " 9. UTIL   Josh Donaldson               3B    TOR            7.405   5700.0$   \n",
      "\n",
      "Fantasy Points 83.69\n",
      "Salary 46300.00\n",
      "\n",
      "[ Jacob deGrom P (NYM),  Dan Murphy 2B/1B (NYM),  Brian Dozier 2B (MIN),  Nolan Arenado 3B (COL),  Alexei Ramirez SS/P (CHW),  Yoenis Cespedes OF (NYM),  Jose Bautista OF (TOR),  Bryce Harper OF (WAS),  Josh Donaldson 3B (TOR)]\n",
      "83.687\n",
      "46300.0\n"
     ]
    }
   ],
   "source": [
    "optimizer.load_players(players)\n",
    "predicted_best_lineup = next(optimizer.optimize(n=1))\n",
    "\n",
    "print(predicted_best_lineup)\n",
    "print(predicted_best_lineup.players)  # list of players\n",
    "print(predicted_best_lineup.fantasy_points_projection)\n",
    "print(predicted_best_lineup.salary_costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how these players actually performed on the day we picked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotoguru_rand_day = rotoguru[rotoguru['Date'] == rand_day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = []\n",
    "for player in predicted_best_lineup.players:\n",
    "    player_list = str(player).split(\" \")\n",
    "    first_name = player_list[1]\n",
    "    last_name = player_list[2]\n",
    "    \n",
    "    players.append(last_name + \", \" + first_name)\n",
    "    \n",
    "actual_team_performance = rotoguru_rand_day[rotoguru_rand_day['Name_Last_First'].isin(players)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name_Last_First</th>\n",
       "      <th>FD_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>Arenado, Nolan</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>Bautista, Jose</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7823</th>\n",
       "      <td>Cespedes, Yoenis</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10503</th>\n",
       "      <td>deGrom, Jacob</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11277</th>\n",
       "      <td>Donaldson, Josh</td>\n",
       "      <td>-1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11449</th>\n",
       "      <td>Dozier, Brian</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19097</th>\n",
       "      <td>Harper, Bryce</td>\n",
       "      <td>16.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29653</th>\n",
       "      <td>Murphy, Dan</td>\n",
       "      <td>-1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35211</th>\n",
       "      <td>Ramirez, Alexei</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name_Last_First  FD_points\n",
       "1438     Arenado, Nolan       8.00\n",
       "2380     Bautista, Jose      -1.00\n",
       "7823   Cespedes, Yoenis       0.00\n",
       "10503     deGrom, Jacob       4.00\n",
       "11277   Donaldson, Josh      -1.00\n",
       "11449     Dozier, Brian       1.00\n",
       "19097     Harper, Bryce      16.00\n",
       "29653       Murphy, Dan      -1.25\n",
       "35211   Ramirez, Alexei       8.50"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_team_performance[['Name_Last_First', 'FD_points']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.25"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_team_performance['FD_points'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to re-run this and see what the actual best lineup was!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotoguru = rotoguru[rotoguru['Date'] < '2015-09-15']\n",
    "\n",
    "rotoguru.loc[(rotoguru['Pos'] == 'C') | (rotoguru['Pos'] == '1B'), 'Pos'] = '1B/C'\n",
    "rotoguru.loc[(rotoguru['Pos'] == 'CF') | (rotoguru['Pos'] == 'LF') | (rotoguru['Pos'] == 'RF'), 'Pos'] = 'OF'\n",
    "rotoguru.loc[rotoguru['Pos'] == 'DH', 'Pos'] = 'UTIL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "PulpSolverError",
     "evalue": "Pulp: Error while executing C:\\Users\\Chris\\Anaconda3\\envs\\si671\\lib\\site-packages\\pulp\\solverdir\\cbc\\win\\64\\cbc.exe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPulpSolverError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-39933b64ee32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_players\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_players\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mlineup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0msecond_base\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlineup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\si671\\lib\\site-packages\\pydfs_lineup_optimizer\\lineup_optimizer.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, n, max_exposure, randomness, with_injured)\u001b[0m\n\u001b[0;32m    372\u001b[0m                 \u001b[0mconstraint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_for_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplayers_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_lineup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m                 \u001b[0msolved_variables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m                 \u001b[0mlineup_players\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0msolved_variable\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msolved_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\si671\\lib\\site-packages\\pydfs_lineup_optimizer\\solvers\\pulp_solver.py\u001b[0m in \u001b[0;36msolve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mLpStatusOptimal\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\si671\\lib\\site-packages\\pulp\\pulp.py\u001b[0m in \u001b[0;36msolve\u001b[1;34m(self, solver, **kwargs)\u001b[0m\n\u001b[0;32m   1669\u001b[0m         \u001b[1;31m#time it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1670\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutionTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1671\u001b[1;33m         \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactualSolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1672\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolutionTime\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1673\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestoreObjective\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwasNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummyVar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\si671\\lib\\site-packages\\pulp\\solvers.py\u001b[0m in \u001b[0;36mactualSolve\u001b[1;34m(self, lp, **kwargs)\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mactualSolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \u001b[1;34m\"\"\"Solve a well formulated lp problem\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1362\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve_CBC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mavailable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\si671\\lib\\site-packages\\pulp\\solvers.py\u001b[0m in \u001b[0;36msolve_CBC\u001b[1;34m(self, lp, use_mps)\u001b[0m\n\u001b[0;32m   1425\u001b[0m                                     self.path)\n\u001b[0;32m   1426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmpSol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1427\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mPulpSolverError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Pulp: Error while executing \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1428\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0muse_mps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m             lp.status, values, reducedCosts, shadowPrices, slacks = self.readsol_MPS(\n",
      "\u001b[1;31mPulpSolverError\u001b[0m: Pulp: Error while executing C:\\Users\\Chris\\Anaconda3\\envs\\si671\\lib\\site-packages\\pulp\\solverdir\\cbc\\win\\64\\cbc.exe"
     ]
    }
   ],
   "source": [
    "dates = list(rotoguru.Date.unique())\n",
    "\n",
    "second_base = []\n",
    "\n",
    "for date in dates[0:1]:\n",
    "    real_players = list(rotoguru[rotoguru.Date == date].apply(get_player_object_real, axis=1))\n",
    "    optimizer.load_players(real_players)\n",
    "\n",
    "    for lineup in optimizer.optimize(n=1):\n",
    "        second_base.append(lineup.players[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "[ Jonathan Schoop 2B (BAL),  Phillip Gosselin 2B (ARI),  Stephen Drew 2B (NYY)]"
      ],
      "text/plain": [
       "[ Jonathan Schoop 2B (BAL),  Phillip Gosselin 2B (ARI),  Stephen Drew 2B (NYY)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Jonathan Schoop 2B (BAL)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Anaconda3\\envs\\si671\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. P      Stephen Strasburg            P     WAS            26.0    10100.0$  \n",
      " 2. C/1B   Mike Olt                     3B/1B CHW            0.25    2200.0$   \n",
      " 3. 2B     Dee Gordon                   2B    MIA            10.75   3600.0$   \n",
      " 4. 3B     Manny Machado                3B    BAL            8.25    3500.0$   \n",
      " 5. SS     Marcus Semien                SS    OAK            9.5     2900.0$   \n",
      " 6. OF     Bryce Harper                 OF    WAS            16.0    5300.0$   \n",
      " 7. OF     Jason Heyward                OF    STL            14.75   3200.0$   \n",
      " 8. OF     A.J. Pollock                 OF    ARI            10.25   3700.0$   \n",
      " 9. UTIL   Josh Reddick                 OF    OAK            12.5    2400.0$   \n",
      "\n",
      "Fantasy Points 108.25\n",
      "Salary 36900.00\n",
      "\n",
      "[ Stephen Strasburg P (WAS),  Mike Olt 3B/1B (CHW),  Dee Gordon 2B (MIA),  Manny Machado 3B (BAL),  Marcus Semien SS (OAK),  Bryce Harper OF (WAS),  Jason Heyward OF (STL),  A.J. Pollock OF (ARI),  Josh Reddick OF (OAK)]\n",
      "108.25\n",
      "36900.0\n"
     ]
    }
   ],
   "source": [
    "rotoguru_rand_day = rotoguru[rotoguru['Date'] == rand_day]\n",
    "\n",
    "rotoguru_rand_day.loc[(rotoguru_rand_day['Pos'] == 'C') | (rotoguru_rand_day['Pos'] == '1B'), 'Pos'] = '1B/C'\n",
    "rotoguru_rand_day.loc[(rotoguru_rand_day['Pos'] == 'CF') | (rotoguru_rand_day['Pos'] == 'LF') | (rotoguru_rand_day['Pos'] == 'RF'), 'Pos'] = 'OF'\n",
    "rotoguru_rand_day.loc[rotoguru_rand_day['Pos'] == 'DH', 'Pos'] = 'UTIL'\n",
    "\n",
    "real_players = list(rotoguru_rand_day.apply(get_player_object_real, axis=1))\n",
    "\n",
    "optimizer.load_players(real_players)\n",
    "for lineup in optimizer.optimize(n=1):\n",
    "    print(lineup)\n",
    "    print(lineup.players)  # list of players\n",
    "    print(lineup.fantasy_points_projection)\n",
    "    print(lineup.salary_costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will be used to create a pydfs Player object from every row of the prediction database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_object(row):\n",
    "    #get the positions\n",
    "    pos_list = []\n",
    "    for pos in row['Pos'].split('-'):\n",
    "        pos_list.append(pos)\n",
    "        \n",
    "    p = Player(player_id = row['key_mlbam'], first_name = row['first_name'], last_name=row['last_name'], positions = pos_list,\n",
    "              team=row['Team'], salary=row['FD_salary'], fppg=row['fd_score'])\n",
    "    \n",
    "    return p\n",
    "\n",
    "def get_player_object_real(row):\n",
    "    #get the positions\n",
    "    pos_list = []\n",
    "    for pos in row['Pos'].split('-'):\n",
    "        pos_list.append(pos)\n",
    "        \n",
    "    p = Player(player_id = row['MLB_ID'], first_name = row['first_name'], last_name=row['last_name'], positions = pos_list,\n",
    "              team=row['Team'], salary=row['FD_salary'], fppg=row['FD_points'])\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
